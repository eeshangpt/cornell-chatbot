{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f2369b",
   "metadata": {},
   "source": [
    "# Report\n",
    "- Eeshan Gupta\n",
    "- eeshangpt@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c7de7",
   "metadata": {},
   "source": [
    "> **Note:** I have wriiten the code in a `.py` file finding it easier to debug and write the code. I am importing the function that drives all my code including the preprocessing. I have also uploaded all the code on github. This file just runs the code. All the explanation is also mentioned as logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb106b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tur1n9/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c491bfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "[2021-12-01 21:30:01,425] [CHATBOT.driver.__get_dialogs] [INFO    ]: Attempting to read pickles of processed dialogs and replies.\n",
      "[2021-12-01 21:30:01,435] [CHATBOT.driver.__get_dialogs] [WARNING ]: Files already present.\n",
      "[2021-12-01 21:30:01,573] [CHATBOT.driver.__get_dialogs] [INFO    ]: Files read successfully.\n",
      "[2021-12-01 21:30:01,587] [CHATBOT.driver] [INFO    ]: Initializing tokenizer...\n",
      "[2021-12-01 21:30:01,672] [CHATBOT.driver] [INFO    ]: Initializing embedding...\n",
      "[2021-12-01 21:30:01,672] [GloVeEmbedding.initialize_embedding_dictionary] [INFO    ]: Choosing 100 dimensions.\n",
      "[2021-12-01 21:30:01,673] [GloVeEmbedding.__get_embedding_dictionary] [INFO    ]: Reading the object file.\n",
      "[2021-12-01 21:30:05,570] [CHATBOT.driver.get_embedding_matrix] [INFO    ]: Creating weights for Embedding Layer.\n",
      "[2021-12-01 21:30:06,734] [CHATBOT.driver] [INFO    ]: Creating a Embedding Layer.\n",
      "[2021-12-01 21:30:06,829] [CHATBOT.driver] [INFO    ]: Creating Training Model...\n",
      "2021-12-01 21:30:06.949577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:06.989216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:06.989631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:06.990753: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-01 21:30:06.991836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:06.992208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:06.992527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:07.960362: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:07.960785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:07.961191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-01 21:30:07.961593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4414 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    293600      ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 200),        240800      ['embedding[0][0]']              \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 200),  240800      ['embedding[1][0]',              \n",
      "                                 (None, 200),                     'lstm[0][1]',                   \n",
      "                                 (None, 200)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 2936)   590136      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,365,336\n",
      "Trainable params: 1,071,736\n",
      "Non-trainable params: 293,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 21:30:08.516544: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2431008000 exceeds 10% of free system memory.\n",
      "2021-12-01 21:30:10.623786: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2431008000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 21:30:14.076537: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 81033600 exceeds 10% of free system memory.\n",
      "2021-12-01 21:30:14.076574: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 81033600 exceeds 10% of free system memory.\n",
      "2021-12-01 21:30:14.077656: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 81033600 exceeds 10% of free system memory.\n",
      "2021-12-01 21:30:15.476387: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 11s 198ms/step - loss: 1.7603 - accuracy: 0.8921\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 5s 181ms/step - loss: 0.5124 - accuracy: 0.9194\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.4485 - accuracy: 0.9324\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.3919 - accuracy: 0.9409\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.3378 - accuracy: 0.9475\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.2907 - accuracy: 0.9558\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 0.2512 - accuracy: 0.9618\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.2177 - accuracy: 0.9685\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 5s 173ms/step - loss: 0.1888 - accuracy: 0.9733\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 5s 172ms/step - loss: 0.1639 - accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 5s 171ms/step - loss: 0.1427 - accuracy: 0.9798\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 5s 172ms/step - loss: 0.1247 - accuracy: 0.9823\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.1094 - accuracy: 0.9846\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 5s 178ms/step - loss: 0.0964 - accuracy: 0.9864\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 6s 186ms/step - loss: 0.0847 - accuracy: 0.9880\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 4s 146ms/step - loss: 0.0745 - accuracy: 0.9897\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.0654 - accuracy: 0.9911\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0572 - accuracy: 0.9924\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 2s 62ms/step - loss: 0.0500 - accuracy: 0.9936\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0437 - accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.0380 - accuracy: 0.9961\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0329 - accuracy: 0.9972\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.0282 - accuracy: 0.9982\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0238 - accuracy: 0.9989\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0200 - accuracy: 0.9994\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0166 - accuracy: 0.9996\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0136 - accuracy: 0.9998\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0111 - accuracy: 0.9999\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0090 - accuracy: 0.9999\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0072 - accuracy: 0.9999\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0058 - accuracy: 0.9999\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 8.3197e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 6.8140e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 5.6639e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 4.7015e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 3.9524e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 3.2972e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 2.8661e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 2.4707e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 2.1226e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 1.7895e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 1.6230e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-01 21:32:43,498] [CHATBOT.driver] [INFO    ]: Creating Infernece Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-01 21:34:47,110] [CHATBOT.driver] [INFO    ]: Generating a reply...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply>>>  start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start\n",
      ">>> start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-01 21:35:00,006] [CHATBOT.driver] [INFO    ]: Generating a reply...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply>>>  start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start\n",
      ">>> hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-12-01 21:35:08,091] [CHATBOT.driver] [INFO    ]: Generating a reply...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reply>>>  start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start start\n",
      ">>> q\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'q'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19353/315015588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogger_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CHATBOT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger_main\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogger_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_line\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NITW/notes/09_industry_grade_project/model.py\u001b[0m in \u001b[0;36mdriver\u001b[0;34m(logger_main_)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time taken to create an inference model is {timer() - start} seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mstates_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_dialog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mempty_target_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mempty_target_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NITW/notes/09_industry_grade_project/model.py\u001b[0m in \u001b[0;36mstr_to_tokens\u001b[0;34m(tokenizer, sentence, max_len_dialog)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_dialog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mtokens_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len_dialog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NITW/notes/09_industry_grade_project/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len_dialog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mtokens_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len_dialog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'q'"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(**get_config(logging.INFO, file_logging=False))\n",
    "logger_main = logging.Logger(\"CHATBOT\")\n",
    "logger_main.critical(__doc__)\n",
    "driver(logger_main)\n",
    "logger_main.critical(end_line.__doc__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba3863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
